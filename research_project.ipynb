{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00bd6376-ecd5-417c-a171-7dab4d83bcf1",
   "metadata": {},
   "source": [
    "# 6.8610  PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55c8fd1-ac41-4d6b-a093-d2521f337837",
   "metadata": {},
   "source": [
    "## Install and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69c3a0d-afdb-483d-9b58-506857a470e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from nltk) (2023.8.8)\n",
      "Requirement already satisfied: tqdm in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from click->nltk) (0.4.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from datasets) (1.23.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from datasets) (14.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from datasets) (1.4.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from datasets) (4.64.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.9.2)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.18.0 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from datasets) (0.19.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from aiohttp->datasets) (2.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from huggingface-hub>=0.18.0->datasets) (3.12.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from huggingface-hub>=0.18.0->datasets) (4.7.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from requests>=2.19.0->datasets) (2022.6.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from pandas->datasets) (2022.2.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (4.34.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 2.15.0 requires huggingface-hub>=0.18.0, but you have huggingface-hub 0.17.3 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: filelock in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from transformers[torch]) (3.12.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from transformers[torch]) (0.19.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from transformers[torch]) (1.23.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from transformers[torch]) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from transformers[torch]) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from transformers[torch]) (2023.8.8)\n",
      "Requirement already satisfied: requests in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from transformers[torch]) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from transformers[torch]) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from transformers[torch]) (4.64.0)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.10 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from transformers[torch]) (2.0.1)\n",
      "Requirement already satisfied: accelerate>=0.20.3 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from transformers[torch]) (0.24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\samch\\appdata\\roaming\\python\\python310\\site-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.7.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from packaging>=20.0->transformers[torch]) (3.0.9)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers[torch])\n",
      "  Downloading huggingface_hub-0.17.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: sympy in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from requests->transformers[torch]) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from requests->transformers[torch]) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from requests->transformers[torch]) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from requests->transformers[torch]) (2022.6.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n",
      "Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "   ---------------------------------------- 295.0/295.0 kB 3.7 MB/s eta 0:00:00\n",
      "Installing collected packages: huggingface-hub\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.19.4\n",
      "    Uninstalling huggingface-hub-0.19.4:\n",
      "      Successfully uninstalled huggingface-hub-0.19.4\n",
      "Successfully installed huggingface-hub-0.17.3\n",
      "Requirement already satisfied: tokenizers in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (0.14.1)\n",
      "Requirement already satisfied: huggingface_hub<0.18,>=0.16.4 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from tokenizers) (0.17.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers) (3.12.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers) (2023.9.2)\n",
      "Requirement already satisfied: requests in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers) (4.64.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers) (4.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from packaging>=20.9->huggingface_hub<0.18,>=0.16.4->tokenizers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub<0.18,>=0.16.4->tokenizers) (0.4.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from requests->huggingface_hub<0.18,>=0.16.4->tokenizers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from requests->huggingface_hub<0.18,>=0.16.4->tokenizers) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from requests->huggingface_hub<0.18,>=0.16.4->tokenizers) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from requests->huggingface_hub<0.18,>=0.16.4->tokenizers) (2022.6.15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from evaluate) (2.15.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from evaluate) (1.23.2)\n",
      "Requirement already satisfied: dill in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from evaluate) (0.3.7)\n",
      "Requirement already satisfied: pandas in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from evaluate) (1.4.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from evaluate) (4.64.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from evaluate) (0.70.15)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (2023.9.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from evaluate) (0.17.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from evaluate) (21.3)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from datasets>=2.0.0->evaluate) (14.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.8.5)\n",
      "Collecting huggingface-hub>=0.7.0 (from evaluate)\n",
      "  Using cached huggingface_hub-0.19.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.7.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from packaging->evaluate) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from requests>=2.19.0->evaluate) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from requests>=2.19.0->evaluate) (2022.6.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from pandas->evaluate) (2022.2.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
      "Using cached huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
      "Installing collected packages: huggingface-hub\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.17.3\n",
      "    Uninstalling huggingface-hub-0.17.3:\n",
      "      Successfully uninstalled huggingface-hub-0.17.3\n",
      "Successfully installed huggingface-hub-0.19.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\samch\\micromambaenv\\envs\\cs109a\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tokenizers 0.14.1 requires huggingface_hub<0.18,>=0.16.4, but you have huggingface-hub 0.19.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install datasets\n",
    "!pip install transformers[torch]\n",
    "!pip install tokenizers\n",
    "!pip install evaluate\n",
    "!pip install rouge_score\n",
    "!pip install sentencepiece\n",
    "!pip install huggingface_hub\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673e826c-17f9-45cf-b600-a0a41d8a33e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "from transformers import T5Tokenizer, DataCollatorForSeq2Seq\n",
    "from transformers import T5ForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import pandas as pd\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f60ea4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a64e28-68b5-489d-97b4-139cbb60c837",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0a323b-428f-4ca2-88d9-3bd4145031ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"t5-base\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486f8f8f-24af-4ada-addd-a65f1cda6338",
   "metadata": {},
   "source": [
    "## Create datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f3e5ce-60d4-4910-a253-43809da4be7f",
   "metadata": {},
   "source": [
    "### Create code dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb437f7-ae45-41ad-9029-e3b87d133e8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_text_before_example(text):\n",
    "    return text.split(\"**Example 1:**\")[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5cb0b6-228d-45a0-9e72-4dba309f94c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_folder_to_datasetdict_code(folder_path):\n",
    "    with open(folder_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    df = pd.json_normalize(data)\n",
    "    dataset = Dataset.from_pandas(df[['code_with_problem', 'code_only']])\n",
    "    dataset['question'] = dataset['code_with_problem'].apply(extract_text_before_example)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c13de88-ac92-411a-b2e4-f5fbc031f882",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_folder_to_datasetdict_code(folder_path):\n",
    "    with open(folder_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    df = pd.json_normalize(data)\n",
    "\n",
    "    # Extract text before \"Example 1\" for the 'code_with_problem' column\n",
    "    df['question'] = df['code_with_problem'].apply(extract_text_before_example)\n",
    "\n",
    "    # Rename columns and create the dataset\n",
    "    df.rename(columns={'code_only': 'answer'}, inplace=True)\n",
    "    dataset = Dataset.from_pandas(df[['question', 'answer']])\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7801c5e5-ca37-4247-b821-0e636bde1f3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "code_dataset = convert_folder_to_datasetdict_code('data/code/leetcode-solutions.json')\n",
    "train_dataset, test_dataset = train_test_split(code_dataset, test_size=0.2)\n",
    "train_dataset = Dataset.from_dict(train_dataset)\n",
    "test_dataset = Dataset.from_dict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03217e55-403e-49f4-809e-98c00df21937",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "code_dict = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'test': test_dataset\n",
    "})\n",
    "\n",
    "print(code_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1fe247-c841-4170-94c8-d97a89877b0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_train = code_dict['train'].num_rows\n",
    "n_test = code_dict['test'].num_rows\n",
    "n_total = n_train + n_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a43a410-aa83-46d1-a752-6e3b0387a9f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "code_dict[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0633e05f-5423-4e20-8c09-1346d19ef328",
   "metadata": {},
   "source": [
    "### Create general knowledge dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b8c412-f8a8-4fa8-ab4a-5bea2ae894a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_file_path = 'data/general/general.csv'\n",
    "general = pd.read_csv(csv_file_path)\n",
    "general = general.sample(n=n_total, random_state=42)\n",
    "general['id'] = range(len(general))\n",
    "train_sample, test_sample = train_test_split(general, test_size=0.2, random_state=42)\n",
    "train_sample.reset_index(drop=True, inplace=True)\n",
    "test_sample.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_sample[['question', 'answer']])\n",
    "test_dataset = Dataset.from_pandas(test_sample[['question', 'answer']])\n",
    "\n",
    "general_dict = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'test': test_dataset,\n",
    "})\n",
    "\n",
    "print(general_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57afb3e1-c17b-4ebe-846b-d82948014f44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "general_dict[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c723f352-aa2e-430f-b835-239807af143e",
   "metadata": {},
   "source": [
    "### Create math dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c35803-3c0b-44c0-900b-a5c70864de2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_folder_to_datasetdict_math(folder_path):\n",
    "    #data = {\"id\": [], \"question\": [], \"level\": [], \"type\": [], \"answer\": []}\n",
    "    data = {\"question\": [], \"answer\": []}\n",
    "\n",
    "    subject_dictionary = {\n",
    "        \"algebra\": 1,\n",
    "        \"counting_and_probability\": 2,\n",
    "        \"geometry\": 3,\n",
    "        \"intermediate_algebra\": 4,\n",
    "        \"number_theory\": 5,\n",
    "        \"prealgebra\": 6,\n",
    "        \"precalculus\": 7\n",
    "    }\n",
    "\n",
    "    for subdir, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            folder_name = os.path.basename(os.path.normpath(subdir))\n",
    "            \n",
    "            with open(file_path, \"r\") as f:\n",
    "                json_data = json.load(f)\n",
    "                problem = json_data.get(\"problem\", \"\")\n",
    "                level = json_data.get(\"level\", \"\")\n",
    "                type_ = json_data.get(\"type\", \"\")\n",
    "                solution = json_data.get(\"solution\", \"\")\n",
    "\n",
    "                # Generate id from subject code and file name\n",
    "                file_name = os.path.splitext(file)[0]\n",
    "                subject_code = subject_dictionary.get(folder_name, 0)  # Default to 0 if not found\n",
    "                id_ = f\"{subject_code}_{file_name}\"\n",
    "\n",
    "                #data[\"id\"].append(id_)\n",
    "                data[\"question\"].append(problem)\n",
    "                #data[\"level\"].append(level)\n",
    "                #data[\"type\"].append(type_)\n",
    "                data[\"answer\"].append(solution)\n",
    "\n",
    "    dataset = Dataset.from_dict(data)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee114fa9-509b-47d1-9039-ca0679324080",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "math_train = convert_folder_to_datasetdict_math(\"data/math/train/\")\n",
    "math_test = convert_folder_to_datasetdict_math(\"data/math/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820af25a-2806-4cbe-be23-107fc02f632f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "math_train = math_train.shuffle(seed=42)\n",
    "math_train = math_train.select(range(n_train))\n",
    "\n",
    "math_test = math_test.shuffle(seed=42)\n",
    "math_test = math_test.select(range(n_test))\n",
    "\n",
    "math_dict = DatasetDict({\n",
    "    'train': math_train,\n",
    "    'test': math_test\n",
    "})\n",
    "\n",
    "print(math_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a46830-2716-495d-a669-87c046816932",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "math_dict[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed79018d-53d9-4042-98d7-3f715aea4ca9",
   "metadata": {},
   "source": [
    "### Create 50% samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e4c8b9-adfa-4f8a-a7ad-c0a7a3504f7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "math_train_sample = math_dict['train'].shuffle(seed=42).select([i for i in range(math_dict['train'].num_rows // 2)])\n",
    "math_test_sample = math_dict['test'].shuffle(seed=42).select([i for i in range(math_dict['test'].num_rows // 2)])\n",
    "\n",
    "general_train_sample = general_dict['train'].shuffle(seed=42).select([i for i in range(general_dict['train'].num_rows // 2+1)])\n",
    "general_test_sample = general_dict['test'].shuffle(seed=42).select([i for i in range(general_dict['test'].num_rows // 2)])\n",
    "\n",
    "code_train_sample = code_dict['train'].shuffle(seed=42).select([i for i in range(code_dict['train'].num_rows // 2)])\n",
    "code_test_sample = code_dict['test'].shuffle(seed=42).select([i for i in range(code_dict['test'].num_rows // 2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74577ff-b47a-4c4a-bb30-779c72336122",
   "metadata": {},
   "source": [
    "### Create 50% general 50% math dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cbcd89-e9ff-4f64-b38f-8b82f96a31eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "general_math_dict = DatasetDict({\n",
    "    'train': Dataset.from_dict({\n",
    "        'question': math_train_sample['question'] + general_train_sample['question'],\n",
    "        'answer': math_train_sample['answer'] + general_train_sample['answer'],\n",
    "    }),\n",
    "    'test': Dataset.from_dict({\n",
    "        'question': math_test_sample['question'] + general_test_sample['question'],\n",
    "        'answer': math_test_sample['answer'] + general_test_sample['answer'],\n",
    "    })\n",
    "})\n",
    "\n",
    "\n",
    "general_math_dict = DatasetDict({\n",
    "    'train': general_math_dict['train'].shuffle(seed=42),\n",
    "    'test': general_math_dict['test'].shuffle(seed=42)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882a1fc2-3d94-4836-8a1d-c2eea04fd356",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "general_math_dict[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48b6262-6ee4-43e1-bd63-564fc5817642",
   "metadata": {},
   "source": [
    "### Create 50% general 50% code dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6fb1f1-c1f0-4860-9f28-e0229cde7487",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "general_code_dict = DatasetDict({\n",
    "    'train': Dataset.from_dict({\n",
    "        'question': code_train_sample['question'] + general_train_sample['question'],\n",
    "        'answer': code_train_sample['answer'] + general_train_sample['answer'],\n",
    "    }),\n",
    "    'test': Dataset.from_dict({\n",
    "        'question': code_test_sample['question'] + general_test_sample['question'],\n",
    "        'answer': code_test_sample['answer'] + general_test_sample['answer'],\n",
    "    })\n",
    "})\n",
    "\n",
    "general_code_dict = DatasetDict({\n",
    "    'train': general_code_dict['train'].shuffle(seed=42),\n",
    "    'test': general_code_dict['test'].shuffle(seed=42)\n",
    "})\n",
    "\n",
    "print(general_code_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc493dae-6232-483a-98b7-2413a0148097",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "general_code_dict[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e8c09e-ee35-48ca-a7d3-56de23bf74be",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Different Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c291ef2-8c73-41d7-a49a-82d220fd4ce4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def smaller_df(train, test, num_train = 500, seed = 42):\n",
    "    num_test = int(((100*num_train)/80) - num_train) #to get 20% test\n",
    "\n",
    "    train_small = train.shuffle(seed = seed).select(range(num_train))\n",
    "    test_small = test.shuffle(seed = seed).select(range(num_test))\n",
    "    \n",
    "    dict_final =  DatasetDict({\n",
    "    'train': train_small,\n",
    "    'test': test_small\n",
    "})\n",
    "    \n",
    "    return dict_final, train_small, test_small\n",
    "                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726b2c12-456f-4da1-be2d-a39b68681bff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### General Knwoledge/Facts\n",
    "general_dict_small, general_train_small, general_test_small = smaller_df(general_dict['train'],\n",
    "                                                                         general_dict['test'])\n",
    "\n",
    "##Math\n",
    "math_dict_small, math_train_small, math_test_small = smaller_df(math_train, math_test)\n",
    "\n",
    "### Code\n",
    "code_dict_small, code_train_small, code_test_small = smaller_df(code_dict['train'], code_dict['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5977fd4e-3fa5-4eff-b855-3af20d8d5288",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c905e62b-8fa0-40a1-8441-041309ba0bd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prefix = \"Please answer this question: \"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "   \"\"\"Add prefix to the sentences, tokenize the text, and set the labels\"\"\"\n",
    "   # The \"inputs\" are the tokenized answer:\n",
    "   inputs = [prefix + doc for doc in examples[\"question\"]]\n",
    "   model_inputs = tokenizer(inputs, max_length=128, truncation=True)\n",
    "  \n",
    "   # The \"labels\" are the tokenized outputs:\n",
    "   labels = tokenizer(text_target=examples[\"answer\"], \n",
    "                      max_length=512,         \n",
    "                      truncation=True)\n",
    "\n",
    "   model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "   return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5355b55-7f8e-45a2-b6d1-91357968dedf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_dataset_math = math_dict.map(preprocess_function, batched=True)\n",
    "tokenized_dataset_code = code_dict.map(preprocess_function, batched=True)\n",
    "tokenized_dataset_general = general_dict.map(preprocess_function, batched=True)\n",
    "tokenized_dataset_general_code = general_code_dict.map(preprocess_function, batched=True)\n",
    "tokenized_dataset_general_math = general_math_dict.map(preprocess_function, batched=True)\n",
    "\n",
    "### Smaller Models\n",
    "tokenized_dataset_math_small = math_dict_small.map(preprocess_function, batched=True)\n",
    "tokenized_dataset_code_small = code_dict_small.map(preprocess_function, batched=True)\n",
    "tokenized_dataset_general_small = general_dict_small.map(preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd0266-9885-42ed-8a12-0de5a8cd1070",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nltk.download(\"punkt\", quiet=True)\n",
    "metric = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd4453a-5b62-4c43-be98-911e0d460396",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "   preds, labels = eval_preds\n",
    "\n",
    "   # decode preds and labels\n",
    "   labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "   decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "   decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "   # rougeLSum expects newline after each sentence\n",
    "   decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "   decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "\n",
    "   result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "  \n",
    "   return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecbb6b0-9938-4584-a913-d523357eb3c6",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae9a639-1778-4713-abe2-945221bee480",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d461a46b-1029-4a02-9ecf-4bbde555e235",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def training_args(output_dir, L_RATE = 3e-4, BATCH_SIZE = 4, PER_DEVICE_EVAL_BATCH = 4, WEIGHT_DECAY = 0.01, SAVE_TOTAL_LIM = 3, NUM_EPOCHS = 3, OVERWRITE_OUTPUT_DIR = True, LOAD_BEST_MODEL_AT_END = True):\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "       output_dir=output_dir,\n",
    "       overwrite_output_dir=OVERWRITE_OUTPUT_DIR,\n",
    "       save_strategy=\"epoch\",\n",
    "       evaluation_strategy=\"epoch\",\n",
    "       load_best_model_at_end=LOAD_BEST_MODEL_AT_END,\n",
    "       learning_rate=L_RATE,\n",
    "       per_device_train_batch_size=BATCH_SIZE,\n",
    "       per_device_eval_batch_size=PER_DEVICE_EVAL_BATCH,\n",
    "       weight_decay=WEIGHT_DECAY,\n",
    "       save_total_limit=SAVE_TOTAL_LIM,\n",
    "       num_train_epochs=NUM_EPOCHS,\n",
    "       predict_with_generate=True,\n",
    "       push_to_hub=False\n",
    "    )\n",
    "    return training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7a5c09-7624-49f3-992b-1b402c268694",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lrs = [3e-3, 3e-4, 3e-5] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21401d56-7d78-4038-96a3-f8e0f6b44525",
   "metadata": {},
   "source": [
    "### Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb02c39-54c8-4d83-baa1-0ffe30383c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr in lrs:\n",
    "    model_math = T5ForConditionalGeneration.from_pretrained(MODEL_NAME).to(device)\n",
    "    data_collator_math = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_math)\n",
    "    \n",
    "    output_dir_root = \"./results/math\"\n",
    "    output_dir = f\"{output_dir_root}/{lr:.0e}\".replace(\"0\", \"\")\n",
    "    training_args_math = training_args(L_RATE = lr, BATCH_SIZE = 4, NUM_EPOCHS = 3, output_dir=output_dir)\n",
    "\n",
    "    trainer_math = Seq2SeqTrainer(\n",
    "       model=model_math,\n",
    "       args=training_args_math,\n",
    "       train_dataset=tokenized_dataset_math[\"train\"], \n",
    "       eval_dataset=tokenized_dataset_math[\"test\"],   \n",
    "       tokenizer=tokenizer,\n",
    "       data_collator=data_collator_math,\n",
    "       compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer_math.train()\n",
    "\n",
    "    del model_math\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d841d885-c881-422c-ade2-90c26745c70d",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a56e89-3e6c-4155-8293-7f7a9bf44d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr in lrs:\n",
    "    model_code = T5ForConditionalGeneration.from_pretrained(MODEL_NAME).to(device)\n",
    "    data_collator_code = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_code)\n",
    "    \n",
    "    output_dir_root = \"./results/code\"\n",
    "    output_dir = f\"{output_dir_root}/{lr:.0e}\".replace(\"0\", \"\")\n",
    "    training_args_code = training_args(L_RATE = lr, BATCH_SIZE = 4, NUM_EPOCHS = 3, output_dir=output_dir)\n",
    "\n",
    "    trainer_code = Seq2SeqTrainer(\n",
    "       model=model_code,\n",
    "       args=training_args_code,\n",
    "       train_dataset=tokenized_dataset_code[\"train\"], \n",
    "       eval_dataset=tokenized_dataset_code[\"test\"],   \n",
    "       tokenizer=tokenizer,\n",
    "       data_collator=data_collator_code,\n",
    "       compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer_code.train()\n",
    "\n",
    "    del model_code\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b35f10-0a68-4a87-a967-c296629f6b32",
   "metadata": {},
   "source": [
    "### General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732bb296-b51f-4715-9b3d-d5800246c0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr in lrs:\n",
    "    model_general = T5ForConditionalGeneration.from_pretrained(MODEL_NAME).to(device)\n",
    "    data_collator_general = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_general)\n",
    "\n",
    "    output_dir_root = \"./results/general\"\n",
    "    output_dir = f\"{output_dir_root}/{lr:.0e}\".replace(\"0\", \"\")\n",
    "    training_args_general = training_args(L_RATE = lr, BATCH_SIZE = 4, NUM_EPOCHS = 3, output_dir=output_dir)\n",
    "\n",
    "    trainer_general = Seq2SeqTrainer(\n",
    "       model=model_general,\n",
    "       args=training_args_general,\n",
    "       train_dataset=tokenized_dataset_general[\"train\"], \n",
    "       eval_dataset=tokenized_dataset_general[\"test\"],   \n",
    "       tokenizer=tokenizer,\n",
    "       data_collator=data_collator_general,\n",
    "       compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer_general.train()\n",
    "\n",
    "    del model_general\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b818c67-6b6b-4ce3-b43a-9a5eb3d57695",
   "metadata": {},
   "source": [
    "### General + Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dc5804-50f2-46e0-9192-971b0a153f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr in lrs:\n",
    "    model_general_code = T5ForConditionalGeneration.from_pretrained(MODEL_NAME).to(device)\n",
    "    data_collator_general_code = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_general_code)\n",
    "\n",
    "    output_dir_root = \"./results/general_code\"\n",
    "    output_dir = f\"{output_dir_root}/{lr:.0e}\".replace(\"0\", \"\")\n",
    "    training_args_general_code = training_args(L_RATE = lr, BATCH_SIZE = 4, NUM_EPOCHS = 3, output_dir=output_dir)\n",
    "\n",
    "    trainer_general_code = Seq2SeqTrainer(\n",
    "       model=model_general_code,\n",
    "       args=training_args_general_code,\n",
    "       train_dataset=tokenized_dataset_general_code[\"train\"], \n",
    "       eval_dataset=tokenized_dataset_general_code[\"test\"],   \n",
    "       tokenizer=tokenizer,\n",
    "       data_collator=data_collator_general_code,\n",
    "       compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer_general_code.train()\n",
    "\n",
    "    del model_general_code\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9843366a-5d48-4364-bc58-4cccc0f2c5c8",
   "metadata": {},
   "source": [
    "### General + Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5b87f6-d73f-4aa4-bc80-28ee764a0006",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr in lrs:\n",
    "    model_general_math = T5ForConditionalGeneration.from_pretrained(MODEL_NAME).to(device)\n",
    "    data_collator_general_math = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_general_math)\n",
    "\n",
    "    output_dir_root = \"./results/general_math\"\n",
    "    output_dir = f\"{output_dir_root}/{lr:.0e}\".replace(\"0\", \"\")\n",
    "    training_args_general_math = training_args(L_RATE = lr, BATCH_SIZE = 4, NUM_EPOCHS = 3, output_dir=output_dir)\n",
    "\n",
    "    trainer_general_math = Seq2SeqTrainer(\n",
    "       model=model_general_math,\n",
    "       args=training_args_general_math,\n",
    "       train_dataset=tokenized_dataset_general_math[\"train\"], \n",
    "       eval_dataset=tokenized_dataset_general_math[\"test\"],   \n",
    "       tokenizer=tokenizer,\n",
    "       data_collator=data_collator_general_math,\n",
    "       compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer_general_math.train()\n",
    "\n",
    "    del model_general_math\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8eef4a-f4af-48f2-afe0-9a67550e6ce9",
   "metadata": {},
   "source": [
    "### Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fe975a-650e-4a1f-b1f1-9106b7083ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = [3e-4] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d26117-84cf-4db3-9f9e-f7afc999bebc",
   "metadata": {},
   "source": [
    "#### 1. Small Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da559dd3-6d6e-47de-b71e-2c8c30891737",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for lr in lrs:\n",
    "    model_small_math = T5ForConditionalGeneration.from_pretrained(MODEL_NAME).to(device)\n",
    "    data_collator_math_small = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_small_math)\n",
    "    \n",
    "    output_dir_root = \"./results/small_math\"\n",
    "    output_dir = f\"{output_dir_root}/{lr:.0e}\".replace(\"0\", \"\")\n",
    "    training_args_math_small = training_args(L_RATE = lr, BATCH_SIZE = 4, NUM_EPOCHS = 3, output_dir=output_dir)\n",
    "\n",
    "    trainer_math_small = Seq2SeqTrainer(\n",
    "       model=model_small_math,\n",
    "       args=training_args_math_small,\n",
    "       train_dataset=tokenized_dataset_math_small[\"train\"], \n",
    "       eval_dataset=tokenized_dataset_math_small[\"test\"],   \n",
    "       tokenizer=tokenizer,\n",
    "       data_collator=data_collator_math_small,\n",
    "       compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer_math_small.train()\n",
    "\n",
    "    del model_small_math\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52c865f-4ebe-43dd-adb4-c1ba211927a4",
   "metadata": {},
   "source": [
    "### 2. Code Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b80112-b6e6-4715-a5df-37e7b8f011f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr in lrs:\n",
    "    model_small_code = T5ForConditionalGeneration.from_pretrained(MODEL_NAME).to(device)\n",
    "    data_collator_code_small = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_small_code)\n",
    "    \n",
    "    output_dir_root = \"./results/small_code\"\n",
    "    output_dir = f\"{output_dir_root}/{lr:.0e}\".replace(\"0\", \"\")\n",
    "    training_args_code_small = training_args(L_RATE = lr, BATCH_SIZE = 4, NUM_EPOCHS = 3, output_dir=output_dir)\n",
    "\n",
    "    trainer_code_small = Seq2SeqTrainer(\n",
    "       model=model_small_code,\n",
    "       args=training_args_code_small,\n",
    "       train_dataset=tokenized_dataset_code_small[\"train\"], \n",
    "       eval_dataset=tokenized_dataset_code_small[\"test\"],   \n",
    "       tokenizer=tokenizer,\n",
    "       data_collator=data_collator_code_small,\n",
    "       compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer_code_small.train()\n",
    "\n",
    "    del model_small_code\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91d566f-797e-4073-8ae4-d56726e10eaf",
   "metadata": {},
   "source": [
    "### 3. General Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b8039a-02fd-4d74-8b8f-62e79a021746",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr in lrs:\n",
    "    model_small_general = T5ForConditionalGeneration.from_pretrained(MODEL_NAME).to(device)\n",
    "    data_collator_general_small = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_small_general)\n",
    "\n",
    "    output_dir_root = \"./results/small_general\"\n",
    "    output_dir = f\"{output_dir_root}/{lr:.0e}\".replace(\"0\", \"\")\n",
    "    training_args_general_small = training_args(L_RATE = lr, BATCH_SIZE = 4, NUM_EPOCHS = 3, output_dir=output_dir)\n",
    "\n",
    "    trainer_general_small = Seq2SeqTrainer(\n",
    "       model=model_small_general,\n",
    "       args=training_args_general_small,\n",
    "       train_dataset=tokenized_dataset_general_small[\"train\"], \n",
    "       eval_dataset=tokenized_dataset_general_small[\"test\"],   \n",
    "       tokenizer=tokenizer,\n",
    "       data_collator=data_collator_general_small,\n",
    "       compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer_general_small.train()\n",
    "\n",
    "    del model_small_general\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
