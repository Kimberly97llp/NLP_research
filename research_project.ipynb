{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00bd6376-ecd5-417c-a171-7dab4d83bcf1",
   "metadata": {},
   "source": [
    "# 6.8610  PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55c8fd1-ac41-4d6b-a093-d2521f337837",
   "metadata": {},
   "source": [
    "## Install and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e69c3a0d-afdb-483d-9b58-506857a470e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: datasets in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (1.24.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (14.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.1.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.18.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.19.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.18.0->datasets) (3.12.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.18.0->datasets) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->datasets) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: transformers[torch] in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.35.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (3.12.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (0.19.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (4.66.1)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.10 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (2.1.1+cu118)\n",
      "Requirement already satisfied: accelerate>=0.20.3 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (0.24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\yezix\\appdata\\roaming\\python\\python311\\site-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.5.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers[torch]) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers[torch]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers[torch]) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers[torch]) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: tokenizers in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.15.0)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tokenizers) (0.19.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (3.12.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (23.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub<1.0,>=0.16.4->tokenizers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.7.22)\n",
      "Requirement already satisfied: evaluate in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (2.15.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (1.24.3)\n",
      "Requirement already satisfied: dill in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (0.3.7)\n",
      "Requirement already satisfied: pandas in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (2.1.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (4.66.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (0.70.15)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (2023.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (0.19.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (23.1)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->evaluate) (14.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->evaluate) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->evaluate) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->evaluate) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Requirement already satisfied: rouge_score in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rouge_score) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rouge_score) (1.24.3)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->rouge_score) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->rouge_score) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->rouge_score) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->rouge_score) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click->nltk->rouge_score) (0.4.6)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.1.99)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.19.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (3.12.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (2023.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (4.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (23.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub) (2023.7.22)\n",
      "Requirement already satisfied: wandb in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.16.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (3.1.40)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\yezix\\appdata\\roaming\\python\\python311\\site-packages (from wandb) (5.9.5)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (1.36.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (69.0.2)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (4.24.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install datasets\n",
    "!pip install transformers[torch]\n",
    "!pip install tokenizers\n",
    "!pip install evaluate\n",
    "!pip install rouge_score\n",
    "!pip install sentencepiece\n",
    "!pip install huggingface_hub\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "673e826c-17f9-45cf-b600-a0a41d8a33e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yezix\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import T5Tokenizer, DataCollatorForSeq2Seq\n",
    "from transformers import T5ForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import pandas as pd\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f60ea4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a64e28-68b5-489d-97b4-139cbb60c837",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a0a323b-428f-4ca2-88d9-3bd4145031ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yezix\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\t5\\tokenization_t5.py:240: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"t5-base\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "model_math = T5ForConditionalGeneration.from_pretrained(MODEL_NAME).to(device)\n",
    "model_code1 = T5ForConditionalGeneration.from_pretrained(MODEL_NAME).to(device)\n",
    "model_code2 = T5ForConditionalGeneration.from_pretrained(MODEL_NAME).to(device)\n",
    "model_general = T5ForConditionalGeneration.from_pretrained(MODEL_NAME).to(device)\n",
    "\n",
    "data_collator_math = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_math)\n",
    "data_collator_code1 = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_code1)\n",
    "data_collator_code2 = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_code2)\n",
    "data_collator_general = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_general)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486f8f8f-24af-4ada-addd-a65f1cda6338",
   "metadata": {},
   "source": [
    "## Create datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f3e5ce-60d4-4910-a253-43809da4be7f",
   "metadata": {},
   "source": [
    "### Create code dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f5cb0b6-228d-45a0-9e72-4dba309f94c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_folder_to_datasetdict_code(folder_path):\n",
    "    with open(folder_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    df = pd.json_normalize(data)\n",
    "    #df.rename(columns={'code_with_problem': 'question', 'code_only': 'answer'}, inplace=True)\n",
    "    #dataset = Dataset.from_pandas(df[['question', 'answer']])\n",
    "    dataset = Dataset.from_pandas(df[['code_with_problem', 'code_with_data', 'code_only']])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7801c5e5-ca37-4247-b821-0e636bde1f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_dataset = convert_folder_to_datasetdict_code('data/code/leetcode-solutions.json')\n",
    "train_dataset, test_dataset = train_test_split(code_dataset, test_size=0.2)\n",
    "train_dataset = Dataset.from_dict(train_dataset)\n",
    "test_dataset = Dataset.from_dict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae320bc5-d87c-4a75-8e6c-d43ccc27db5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_dict = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03217e55-403e-49f4-809e-98c00df21937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'answer'],\n",
      "        num_rows: 1887\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['question', 'answer'],\n",
      "        num_rows: 472\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "train_dataset_modified = code_dict['train'].rename_column('code_with_problem', 'question')\n",
    "train_dataset_modified = train_dataset_modified.rename_column('code_only', 'answer')\n",
    "train_dataset_modified = train_dataset_modified.remove_columns('code_with_data')\n",
    "\n",
    "test_dataset_modified = code_dict['test'].rename_column('code_with_problem', 'question')\n",
    "test_dataset_modified = test_dataset_modified.rename_column('code_only', 'answer')\n",
    "test_dataset_modified = test_dataset_modified.remove_columns('code_with_data')\n",
    "\n",
    "code_dict1 = DatasetDict({\n",
    "    'train': train_dataset_modified,\n",
    "    'test': test_dataset_modified\n",
    "})\n",
    "\n",
    "print(code_dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ead256d6-e5f7-465e-bb32-9b473fdadc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'answer'],\n",
      "        num_rows: 1887\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['question', 'answer'],\n",
      "        num_rows: 472\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "train_dataset_modified = code_dict['train'].rename_column('code_with_data', 'question')\n",
    "train_dataset_modified = train_dataset_modified.rename_column('code_only', 'answer')\n",
    "train_dataset_modified = train_dataset_modified.remove_columns('code_with_problem')\n",
    "\n",
    "test_dataset_modified = code_dict['test'].rename_column('code_with_data', 'question')\n",
    "test_dataset_modified = test_dataset_modified.rename_column('code_only', 'answer')\n",
    "test_dataset_modified = test_dataset_modified.remove_columns('code_with_problem')\n",
    "\n",
    "code_dict2 = DatasetDict({\n",
    "    'train': train_dataset_modified,\n",
    "    'test': test_dataset_modified\n",
    "})\n",
    "\n",
    "print(code_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf1fe247-c841-4170-94c8-d97a89877b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = code_dict['train'].num_rows\n",
    "n_test = code_dict['test'].num_rows\n",
    "n_total = n_train + n_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a43a410-aa83-46d1-a752-6e3b0387a9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': '# maximum-side-length-of-a-square-with-sum-less-than-or-equal-to-threshold\\n# Maximum Side Length of a Square with Sum Less than or Equal to Threshold\\n# Medium\\n# Given a `m x n` matrix `mat` and an integer `threshold`, return _the maximum side-length of a square with a sum less than or equal to_ `threshold` _or return_ `0` _if there is no such square_.\\n\\n**Example 1:**\\n\\n**Input:** mat = \\\\[\\\\[1,1,3,2,4,3,2\\\\],\\\\[1,1,3,2,4,3,2\\\\],\\\\[1,1,3,2,4,3,2\\\\]\\\\], threshold = 4\\n**Output:** 2\\n**Explanation:** The maximum side length of square with sum less than 4 is 2 as shown.\\n\\n**Example 2:**\\n\\n**Input:** mat = \\\\[\\\\[2,2,2,2,2\\\\],\\\\[2,2,2,2,2\\\\],\\\\[2,2,2,2,2\\\\],\\\\[2,2,2,2,2\\\\],\\\\[2,2,2,2,2\\\\]\\\\], threshold = 1\\n**Output:** 0\\n\\n**Constraints:**\\n\\n*   `m == mat.length`\\n*   `n == mat[i].length`\\n*   `1 <= m, n <= 300`\\n*   `0 <= mat[i][j] <= 104`\\n*   `0 <= threshold <= 105`\\n```python\\ndef maxSideLength(mat: List[List[int]], threshold: int) -> int:\\n    m, n = len(mat), len(mat[0])\\n    preSum = [[0] * (n + 1) for _ in range(m + 1)]\\n    for i in range(1, m + 1):\\n        for j in range(1, n + 1):\\n            preSum[i][j] = mat[i - 1][j - 1] + preSum[i - 1][j] + preSum[i][j - 1] - preSum[i - 1][j - 1]\\n\\n    maxSide = 0\\n    for i in range(1, m + 1):\\n        for j in range(1, n + 1):\\n            for k in range(1, min(m, n) + 1):\\n                endX, endY = i + k - 1, j + k - 1\\n                if endX <= m and endY <= n:\\n                    sum = preSum[endX][endY] - preSum[endX][j - 1] - preSum[i - 1][endY] + preSum[i - 1][j - 1]\\n                    if sum <= threshold:\\n                        maxSide = max(maxSide, k)\\n                else:\\n                    break\\n    return maxSide\\n```\\n\\n\\n# The goal is to find the maximum side-length of a square with a sum less than or equal to threshold. We first calculate a prefix sum array of size (m+1) x (n+1) where preSum[i][j] stores the sum of all elements in the matrix up to mat[i-1][j-1]. This allows us to calculate the sum of any square in the matrix in constant time.\\n\\nThen, we iterate through each cell in the matrix and try to find a square with maximum side-length whose sum is less than or equal to threshold. We check this for each possible side-length (1 to min(m, n)) by using the prefix sum array.\\n\\nThroughout the iteration, we keep track of the maximum side-length that satisfies the condition sum <= threshold. We return this maximum side-length as the final result. If no square satisfies the condition, the result will be 0.\\n',\n",
       " 'answer': '```python\\ndef maxSideLength(mat: List[List[int]], threshold: int) -> int:\\n    m, n = len(mat), len(mat[0])\\n    preSum = [[0] * (n + 1) for _ in range(m + 1)]\\n    for i in range(1, m + 1):\\n        for j in range(1, n + 1):\\n            preSum[i][j] = mat[i - 1][j - 1] + preSum[i - 1][j] + preSum[i][j - 1] - preSum[i - 1][j - 1]\\n\\n    maxSide = 0\\n    for i in range(1, m + 1):\\n        for j in range(1, n + 1):\\n            for k in range(1, min(m, n) + 1):\\n                endX, endY = i + k - 1, j + k - 1\\n                if endX <= m and endY <= n:\\n                    sum = preSum[endX][endY] - preSum[endX][j - 1] - preSum[i - 1][endY] + preSum[i - 1][j - 1]\\n                    if sum <= threshold:\\n                        maxSide = max(maxSide, k)\\n                else:\\n                    break\\n    return maxSide\\n```\\n\\n\\n'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_dict1[\"train\"][0]\n",
    "code_dict2[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0633e05f-5423-4e20-8c09-1346d19ef328",
   "metadata": {},
   "source": [
    "### Create general knowledge dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96b8c412-f8a8-4fa8-ab4a-5bea2ae894a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'answer'],\n",
      "        num_rows: 1887\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['question', 'answer'],\n",
      "        num_rows: 472\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "csv_file_path = 'data/general/general.csv'\n",
    "general = pd.read_csv(csv_file_path)\n",
    "general = general.sample(n=n_total, random_state=42)\n",
    "general['id'] = range(len(general))\n",
    "train_sample, test_sample = train_test_split(general, test_size=0.2, random_state=42)\n",
    "train_sample.reset_index(drop=True, inplace=True)\n",
    "test_sample.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_sample[['question', 'answer']])\n",
    "test_dataset = Dataset.from_pandas(test_sample[['question', 'answer']])\n",
    "\n",
    "general_dict = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'test': test_dataset,\n",
    "})\n",
    "\n",
    "print(general_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57afb3e1-c17b-4ebe-846b-d82948014f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Add 1 letter to \"Iowa\" to get the name of this tribe who lived south of the Iowa',\n",
       " 'answer': 'Kiowa'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general_dict[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c723f352-aa2e-430f-b835-239807af143e",
   "metadata": {},
   "source": [
    "### Create math dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64c35803-3c0b-44c0-900b-a5c70864de2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_folder_to_datasetdict_math(folder_path):\n",
    "    #data = {\"id\": [], \"question\": [], \"level\": [], \"type\": [], \"answer\": []}\n",
    "    data = {\"question\": [], \"answer\": []}\n",
    "\n",
    "    subject_dictionary = {\n",
    "        \"algebra\": 1,\n",
    "        \"counting_and_probability\": 2,\n",
    "        \"geometry\": 3,\n",
    "        \"intermediate_algebra\": 4,\n",
    "        \"number_theory\": 5,\n",
    "        \"prealgebra\": 6,\n",
    "        \"precalculus\": 7\n",
    "    }\n",
    "\n",
    "    for subdir, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            folder_name = os.path.basename(os.path.normpath(subdir))\n",
    "            \n",
    "            with open(file_path, \"r\") as f:\n",
    "                json_data = json.load(f)\n",
    "                problem = json_data.get(\"problem\", \"\")\n",
    "                level = json_data.get(\"level\", \"\")\n",
    "                type_ = json_data.get(\"type\", \"\")\n",
    "                solution = json_data.get(\"solution\", \"\")\n",
    "\n",
    "                # Generate id from subject code and file name\n",
    "                file_name = os.path.splitext(file)[0]\n",
    "                subject_code = subject_dictionary.get(folder_name, 0)  # Default to 0 if not found\n",
    "                id_ = f\"{subject_code}_{file_name}\"\n",
    "\n",
    "                #data[\"id\"].append(id_)\n",
    "                data[\"question\"].append(problem)\n",
    "                #data[\"level\"].append(level)\n",
    "                #data[\"type\"].append(type_)\n",
    "                data[\"answer\"].append(solution)\n",
    "\n",
    "    dataset = Dataset.from_dict(data)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee114fa9-509b-47d1-9039-ca0679324080",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_train = convert_folder_to_datasetdict_math(\"data/math/train/\")\n",
    "math_test = convert_folder_to_datasetdict_math(\"data/math/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "820af25a-2806-4cbe-be23-107fc02f632f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'answer'],\n",
      "        num_rows: 1887\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['question', 'answer'],\n",
      "        num_rows: 472\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "math_train = math_train.shuffle(seed=42)\n",
    "math_train = math_train.select(range(n_train))\n",
    "\n",
    "math_test = math_test.shuffle(seed=42)\n",
    "math_test = math_test.select(range(n_test))\n",
    "\n",
    "math_dict = DatasetDict({\n",
    "    'train': math_train,\n",
    "    'test': math_test\n",
    "})\n",
    "\n",
    "print(math_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93a46830-2716-495d-a669-87c046816932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the number of units in the distance between $(2,5)$ and $(-6,-1)$?',\n",
       " 'answer': 'We use the distance formula: $\\\\sqrt{(-6 - 2)^2 + (-1 - 5)^2},$ so then we find that $\\\\sqrt{64 + 36} = \\\\boxed{10}$.\\n\\n- OR -\\n\\nWe note that the points $(2, 5)$, $(-6, -1)$, and $(2, -1)$ form a right triangle with legs of length 6 and 8. This is a Pythagorean triple, so the length of the hypotenuse must be $\\\\boxed{10}$.'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_dict[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5977fd4e-3fa5-4eff-b855-3af20d8d5288",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c905e62b-8fa0-40a1-8441-041309ba0bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"Please answer this question: \"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "   \"\"\"Add prefix to the sentences, tokenize the text, and set the labels\"\"\"\n",
    "   # The \"inputs\" are the tokenized answer:\n",
    "   inputs = [prefix + doc for doc in examples[\"question\"]]\n",
    "   model_inputs = tokenizer(inputs, max_length=128, truncation=True)\n",
    "  \n",
    "   # The \"labels\" are the tokenized outputs:\n",
    "   labels = tokenizer(text_target=examples[\"answer\"], \n",
    "                      max_length=512,         \n",
    "                      truncation=True)\n",
    "\n",
    "   model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "   return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5355b55-7f8e-45a2-b6d1-91357968dedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1887/1887 [00:01<00:00, 1098.34 examples/s]\n",
      "Map: 100%|██████████| 472/472 [00:00<00:00, 1102.44 examples/s]\n",
      "Map: 100%|██████████| 1887/1887 [00:02<00:00, 832.68 examples/s]\n",
      "Map: 100%|██████████| 472/472 [00:00<00:00, 825.52 examples/s]\n",
      "Map: 100%|██████████| 1887/1887 [00:00<00:00, 13538.74 examples/s]\n",
      "Map: 100%|██████████| 472/472 [00:00<00:00, 13174.28 examples/s]\n",
      "Map: 100%|██████████| 1887/1887 [00:00<00:00, 2471.16 examples/s]\n",
      "Map: 100%|██████████| 472/472 [00:00<00:00, 2535.50 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset_code1 = code_dict1.map(preprocess_function, batched=True)\n",
    "tokenized_dataset_code2 = code_dict2.map(preprocess_function, batched=True)\n",
    "tokenized_dataset_general = general_dict.map(preprocess_function, batched=True)\n",
    "tokenized_dataset_math = math_dict.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efdd0266-9885-42ed-8a12-0de5a8cd1070",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"punkt\", quiet=True)\n",
    "metric = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cd4453a-5b62-4c43-be98-911e0d460396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "   preds, labels = eval_preds\n",
    "\n",
    "   # decode preds and labels\n",
    "   labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "   decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "   decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "   # rougeLSum expects newline after each sentence\n",
    "   decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "   decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "\n",
    "   result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "  \n",
    "   return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecbb6b0-9938-4584-a913-d523357eb3c6",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9bec7ac9-d105-4fef-8c5e-131c45951ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Parameters\n",
    "L_RATE = 3e-4\n",
    "BATCH_SIZE = 4\n",
    "PER_DEVICE_EVAL_BATCH = 4\n",
    "WEIGHT_DECAY = 0.01\n",
    "SAVE_TOTAL_LIM = 3\n",
    "NUM_EPOCHS = 3\n",
    "OVERWRITE_OUTPUT_DIR = True\n",
    "LOAD_BEST_MODEL_AT_END = True\n",
    "\n",
    "# Set up training arguments\n",
    "training_args_math = Seq2SeqTrainingArguments(\n",
    "   output_dir=\"./results/math\",\n",
    "   overwrite_output_dir=OVERWRITE_OUTPUT_DIR,\n",
    "   save_strategy=\"epoch\",\n",
    "   evaluation_strategy=\"epoch\",\n",
    "   load_best_model_at_end=LOAD_BEST_MODEL_AT_END,\n",
    "   learning_rate=L_RATE,\n",
    "   per_device_train_batch_size=BATCH_SIZE,\n",
    "   per_device_eval_batch_size=PER_DEVICE_EVAL_BATCH,\n",
    "   weight_decay=WEIGHT_DECAY,\n",
    "   save_total_limit=SAVE_TOTAL_LIM,\n",
    "   num_train_epochs=NUM_EPOCHS,\n",
    "   predict_with_generate=True,\n",
    "   push_to_hub=False\n",
    ")\n",
    "\n",
    "training_args_code1 = Seq2SeqTrainingArguments(\n",
    "   output_dir=\"./results/code1\",\n",
    "   overwrite_output_dir=OVERWRITE_OUTPUT_DIR,\n",
    "   save_strategy=\"epoch\",\n",
    "   evaluation_strategy=\"epoch\",\n",
    "   load_best_model_at_end=LOAD_BEST_MODEL_AT_END,\n",
    "   learning_rate=L_RATE,\n",
    "   per_device_train_batch_size=BATCH_SIZE,\n",
    "   per_device_eval_batch_size=PER_DEVICE_EVAL_BATCH,\n",
    "   weight_decay=WEIGHT_DECAY,\n",
    "   save_total_limit=SAVE_TOTAL_LIM,\n",
    "   num_train_epochs=NUM_EPOCHS,\n",
    "   predict_with_generate=True,\n",
    "   push_to_hub=False\n",
    ")\n",
    "\n",
    "training_args_code2 = Seq2SeqTrainingArguments(\n",
    "   output_dir=\"./results/code2\",\n",
    "   overwrite_output_dir=OVERWRITE_OUTPUT_DIR,\n",
    "   save_strategy=\"epoch\",\n",
    "   evaluation_strategy=\"epoch\",\n",
    "   load_best_model_at_end=LOAD_BEST_MODEL_AT_END,\n",
    "   learning_rate=L_RATE,\n",
    "   per_device_train_batch_size=BATCH_SIZE,\n",
    "   per_device_eval_batch_size=PER_DEVICE_EVAL_BATCH,\n",
    "   weight_decay=WEIGHT_DECAY,\n",
    "   save_total_limit=SAVE_TOTAL_LIM,\n",
    "   num_train_epochs=NUM_EPOCHS,\n",
    "   predict_with_generate=True,\n",
    "   push_to_hub=False\n",
    ")\n",
    "\n",
    "training_args_general = Seq2SeqTrainingArguments(\n",
    "   output_dir=\"./results/base\",\n",
    "   overwrite_output_dir=OVERWRITE_OUTPUT_DIR,\n",
    "   save_strategy=\"epoch\",\n",
    "   evaluation_strategy=\"epoch\",\n",
    "   load_best_model_at_end=LOAD_BEST_MODEL_AT_END,\n",
    "   learning_rate=L_RATE,\n",
    "   per_device_train_batch_size=BATCH_SIZE,\n",
    "   per_device_eval_batch_size=PER_DEVICE_EVAL_BATCH,\n",
    "   weight_decay=WEIGHT_DECAY,\n",
    "   save_total_limit=SAVE_TOTAL_LIM,\n",
    "   num_train_epochs=NUM_EPOCHS,\n",
    "   predict_with_generate=True,\n",
    "   push_to_hub=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79eb7ce-d4d2-433b-8deb-bb660067cf59",
   "metadata": {},
   "source": [
    "### Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035495c8-f1ed-49c8-8cee-713de3910148",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_math = Seq2SeqTrainer(\n",
    "   model=model_math,\n",
    "   args=training_args_math,\n",
    "   train_dataset=tokenized_dataset_math[\"train\"], \n",
    "   eval_dataset=tokenized_dataset_math[\"test\"],   \n",
    "   tokenizer=tokenizer,\n",
    "   data_collator=data_collator_math,\n",
    "   compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5a4338-78e9-4357-9b4b-522a9e37ad18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myezixuanclara\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yezix\\Desktop\\2023_Fall\\MIT6.8610\\project\\git\\wandb\\run-20231128_210958-1e5t7wns</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yezixuanclara/huggingface/runs/1e5t7wns' target=\"_blank\">fresh-yogurt-13</a></strong> to <a href='https://wandb.ai/yezixuanclara/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yezixuanclara/huggingface' target=\"_blank\">https://wandb.ai/yezixuanclara/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yezixuanclara/huggingface/runs/1e5t7wns' target=\"_blank\">https://wandb.ai/yezixuanclara/huggingface/runs/1e5t7wns</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 472/1416 [01:49<03:47,  4.15it/s]c:\\Users\\yezix\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "                                                  \n",
      " 33%|███▎      | 472/1416 [02:31<03:47,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7312365770339966, 'eval_rouge1': 0.1519675858878297, 'eval_rouge2': 0.0613339060797851, 'eval_rougeL': 0.1306172730330254, 'eval_rougeLsum': 0.14008236218685827, 'eval_runtime': 42.2795, 'eval_samples_per_second': 11.164, 'eval_steps_per_second': 2.791, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 501/1416 [02:48<03:59,  3.83it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2384, 'learning_rate': 0.00019406779661016945, 'epoch': 1.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 944/1416 [04:44<02:15,  3.48it/s]c:\\Users\\yezix\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "                                                  \n",
      " 67%|██████▋   | 944/1416 [05:26<02:15,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6180236339569092, 'eval_rouge1': 0.1419497361392592, 'eval_rouge2': 0.05908574050106513, 'eval_rougeL': 0.124237828156588, 'eval_rougeLsum': 0.1334857867543956, 'eval_runtime': 41.4327, 'eval_samples_per_second': 11.392, 'eval_steps_per_second': 2.848, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 1001/1416 [05:43<01:05,  6.30it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7438, 'learning_rate': 8.813559322033898e-05, 'epoch': 2.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1416/1416 [07:19<00:00,  3.46it/s]c:\\Users\\yezix\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "                                                   \n",
      "100%|██████████| 1416/1416 [08:02<00:00,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.587369680404663, 'eval_rouge1': 0.15096462116192183, 'eval_rouge2': 0.061661991398463525, 'eval_rougeL': 0.1308013245441378, 'eval_rougeLsum': 0.1403668682057218, 'eval_runtime': 42.7915, 'eval_samples_per_second': 11.03, 'eval_steps_per_second': 2.758, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n",
      "100%|██████████| 1416/1416 [08:13<00:00,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 496.0192, 'train_samples_per_second': 11.413, 'train_steps_per_second': 2.855, 'train_loss': 1.878079990882658, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1416, training_loss=1.878079990882658, metrics={'train_runtime': 496.0192, 'train_samples_per_second': 11.413, 'train_steps_per_second': 2.855, 'train_loss': 1.878079990882658, 'epoch': 3.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_math.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62cb8e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model_math\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41385fbe-3c12-4db7-8e08-3484cecbcd9c",
   "metadata": {},
   "source": [
    "### Code 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff2688bf-59de-448b-be88-84cec4e22588",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_code1 = Seq2SeqTrainer(\n",
    "   model=model_code1,\n",
    "   args=training_args_code1,\n",
    "   train_dataset=tokenized_dataset_code1[\"train\"],    \n",
    "   eval_dataset=tokenized_dataset_code1[\"test\"],    \n",
    "   tokenizer=tokenizer,\n",
    "   data_collator=data_collator_code1,\n",
    "   compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f0f303a-81ea-4ddb-b787-e3c5853976de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myezixuanclara\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yezix\\Desktop\\2023_Fall\\MIT6.8610\\project\\git\\wandb\\run-20231128_212549-fs3dt849</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yezixuanclara/huggingface/runs/fs3dt849' target=\"_blank\">winter-sea-14</a></strong> to <a href='https://wandb.ai/yezixuanclara/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yezixuanclara/huggingface' target=\"_blank\">https://wandb.ai/yezixuanclara/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yezixuanclara/huggingface/runs/fs3dt849' target=\"_blank\">https://wandb.ai/yezixuanclara/huggingface/runs/fs3dt849</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 472/1416 [01:08<02:26,  6.44it/s]c:\\Users\\yezix\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "                                                  \n",
      " 33%|███▎      | 472/1416 [01:47<02:26,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.548426628112793, 'eval_rouge1': 0.11080682240102191, 'eval_rouge2': 0.04262286448926207, 'eval_rougeL': 0.10877352614367107, 'eval_rougeLsum': 0.10891993020584771, 'eval_runtime': 38.24, 'eval_samples_per_second': 12.343, 'eval_steps_per_second': 3.086, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 501/1416 [02:04<02:52,  5.30it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0498, 'learning_rate': 0.00019406779661016945, 'epoch': 1.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 944/1416 [03:25<01:02,  7.61it/s]c:\\Users\\yezix\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "                                                  \n",
      " 67%|██████▋   | 944/1416 [04:04<01:02,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3797942399978638, 'eval_rouge1': 0.11251429177517958, 'eval_rouge2': 0.04183903182471378, 'eval_rougeL': 0.1104787605899227, 'eval_rougeLsum': 0.11062254492669521, 'eval_runtime': 38.0585, 'eval_samples_per_second': 12.402, 'eval_steps_per_second': 3.1, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 1001/1416 [04:19<01:10,  5.89it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4466, 'learning_rate': 8.813559322033898e-05, 'epoch': 2.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1416/1416 [05:24<00:00,  6.57it/s]c:\\Users\\yezix\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "                                                   \n",
      "100%|██████████| 1416/1416 [06:03<00:00,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3264946937561035, 'eval_rouge1': 0.11379369743961823, 'eval_rouge2': 0.04372187033392986, 'eval_rougeL': 0.11183294741338806, 'eval_rougeLsum': 0.11210169735163278, 'eval_runtime': 38.8487, 'eval_samples_per_second': 12.15, 'eval_steps_per_second': 3.037, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n",
      "100%|██████████| 1416/1416 [06:15<00:00,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 377.8306, 'train_samples_per_second': 14.983, 'train_steps_per_second': 3.748, 'train_loss': 1.6090646086439575, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1416, training_loss=1.6090646086439575, metrics={'train_runtime': 377.8306, 'train_samples_per_second': 14.983, 'train_steps_per_second': 3.748, 'train_loss': 1.6090646086439575, 'epoch': 3.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_code1.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4424493",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model_code1, trainer_code1\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf4f37b-4fe4-4f72-a94f-f2a152470428",
   "metadata": {},
   "source": [
    "### Code 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0fa8e107-32a6-4c9f-a0a8-a000484ddedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_code2 = Seq2SeqTrainer(\n",
    "   model=model_code2,\n",
    "   args=training_args_code2,\n",
    "   train_dataset=tokenized_dataset_code2[\"train\"],    \n",
    "   eval_dataset=tokenized_dataset_code2[\"test\"],    \n",
    "   tokenizer=tokenizer,\n",
    "   data_collator=data_collator_code2,\n",
    "   compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59524f6c-a08e-4c20-b387-ab365f4068d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myezixuanclara\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yezix\\Desktop\\2023_Fall\\MIT6.8610\\project\\git\\wandb\\run-20231128_213340-evic1ky8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yezixuanclara/huggingface/runs/evic1ky8' target=\"_blank\">sunny-sun-15</a></strong> to <a href='https://wandb.ai/yezixuanclara/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yezixuanclara/huggingface' target=\"_blank\">https://wandb.ai/yezixuanclara/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yezixuanclara/huggingface/runs/evic1ky8' target=\"_blank\">https://wandb.ai/yezixuanclara/huggingface/runs/evic1ky8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 472/1416 [01:43<03:02,  5.17it/s]c:\\Users\\yezix\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "                                                  \n",
      " 33%|███▎      | 472/1416 [02:51<03:02,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.490283727645874, 'eval_rouge1': 0.11464440722915901, 'eval_rouge2': 0.045900396760247576, 'eval_rougeL': 0.11331536076790824, 'eval_rougeLsum': 0.11363860320917193, 'eval_runtime': 67.7477, 'eval_samples_per_second': 6.967, 'eval_steps_per_second': 1.742, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 501/1416 [03:16<04:16,  3.57it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0369, 'learning_rate': 0.00019406779661016945, 'epoch': 1.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 944/1416 [05:04<01:16,  6.21it/s]c:\\Users\\yezix\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "                                                  \n",
      " 67%|██████▋   | 944/1416 [05:47<01:16,  6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3298611640930176, 'eval_rouge1': 0.11525105091498902, 'eval_rouge2': 0.04818595199598334, 'eval_rougeL': 0.11378199927723637, 'eval_rougeLsum': 0.11388280600541119, 'eval_runtime': 42.9693, 'eval_samples_per_second': 10.985, 'eval_steps_per_second': 2.746, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 1001/1416 [06:21<02:26,  2.83it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4452, 'learning_rate': 8.813559322033898e-05, 'epoch': 2.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1416/1416 [07:56<00:00,  2.96it/s]c:\\Users\\yezix\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "                                                   \n",
      "100%|██████████| 1416/1416 [08:39<00:00,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2836138010025024, 'eval_rouge1': 0.116787621913371, 'eval_rouge2': 0.05169632646560274, 'eval_rougeL': 0.11546628985189317, 'eval_rougeLsum': 0.11574938911925602, 'eval_runtime': 42.1202, 'eval_samples_per_second': 11.206, 'eval_steps_per_second': 2.802, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n",
      "100%|██████████| 1416/1416 [08:55<00:00,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 538.0575, 'train_samples_per_second': 10.521, 'train_steps_per_second': 2.632, 'train_loss': 1.602813677599201, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1416, training_loss=1.602813677599201, metrics={'train_runtime': 538.0575, 'train_samples_per_second': 10.521, 'train_steps_per_second': 2.632, 'train_loss': 1.602813677599201, 'epoch': 3.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_code2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "905175a5-ef86-4832-a1d8-d9ee80108d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model_code2, trainer_code2\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a264ec7-bbb0-4142-b6f8-7fcd12b2e7b1",
   "metadata": {},
   "source": [
    "### General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f3883a6-fd6b-463b-8674-d08f81261ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_general = Seq2SeqTrainer(\n",
    "   model=model_general,\n",
    "   args=training_args_general,\n",
    "   train_dataset=tokenized_dataset_general[\"train\"],    \n",
    "   eval_dataset=tokenized_dataset_general[\"test\"],    \n",
    "   tokenizer=tokenizer,\n",
    "   data_collator=data_collator_general,\n",
    "   compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4dcc2673-534a-4555-9159-a220f860e20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myezixuanclara\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yezix\\Desktop\\2023_Fall\\MIT6.8610\\project\\git\\wandb\\run-20231128_214520-h5owt80m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yezixuanclara/huggingface/runs/h5owt80m' target=\"_blank\">swift-feather-16</a></strong> to <a href='https://wandb.ai/yezixuanclara/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yezixuanclara/huggingface' target=\"_blank\">https://wandb.ai/yezixuanclara/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yezixuanclara/huggingface/runs/h5owt80m' target=\"_blank\">https://wandb.ai/yezixuanclara/huggingface/runs/h5owt80m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 472/1416 [01:02<02:45,  5.70it/s]c:\\Users\\yezix\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "                                                  \n",
      " 33%|███▎      | 472/1416 [01:26<02:45,  5.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7745418548583984, 'eval_rouge1': 0.11132939565142949, 'eval_rouge2': 0.01281779661016949, 'eval_rougeL': 0.11067186697483301, 'eval_rougeLsum': 0.1098510834739648, 'eval_runtime': 24.9347, 'eval_samples_per_second': 18.929, 'eval_steps_per_second': 4.732, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 501/1416 [01:48<02:47,  5.46it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.1223, 'learning_rate': 0.00019406779661016945, 'epoch': 1.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 944/1416 [03:07<01:23,  5.64it/s]c:\\Users\\yezix\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "                                                  \n",
      " 67%|██████▋   | 944/1416 [03:36<01:23,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8065195083618164, 'eval_rouge1': 0.12483368796928113, 'eval_rouge2': 0.018573446327683617, 'eval_rougeL': 0.12515461821605883, 'eval_rougeLsum': 0.12404248294078796, 'eval_runtime': 29.1169, 'eval_samples_per_second': 16.211, 'eval_steps_per_second': 4.053, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 1001/1416 [03:58<01:14,  5.54it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2116, 'learning_rate': 8.813559322033898e-05, 'epoch': 2.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1416/1416 [05:12<00:00,  5.68it/s]c:\\Users\\yezix\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "                                                   \n",
      "100%|██████████| 1416/1416 [05:41<00:00,  5.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8924808502197266, 'eval_rouge1': 0.11745886528725508, 'eval_rouge2': 0.019067796610169493, 'eval_rougeL': 0.1173657733509428, 'eval_rougeLsum': 0.11738381086898031, 'eval_runtime': 28.663, 'eval_samples_per_second': 16.467, 'eval_steps_per_second': 4.117, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n",
      "100%|██████████| 1416/1416 [05:59<00:00,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 361.36, 'train_samples_per_second': 15.666, 'train_steps_per_second': 3.919, 'train_loss': 2.380347041760461, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1416, training_loss=2.380347041760461, metrics={'train_runtime': 361.36, 'train_samples_per_second': 15.666, 'train_steps_per_second': 3.919, 'train_loss': 2.380347041760461, 'epoch': 3.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_general.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19ae22c6-e4dd-4375-a831-f554d61ec308",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model_general\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
