{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00bd6376-ecd5-417c-a171-7dab4d83bcf1",
   "metadata": {},
   "source": [
    "# 6.8610  PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55c8fd1-ac41-4d6b-a093-d2521f337837",
   "metadata": {},
   "source": [
    "## Install and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e69c3a0d-afdb-483d-9b58-506857a470e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: datasets in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (1.24.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (14.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.1.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.18.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.19.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.18.0->datasets) (3.12.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.18.0->datasets) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->datasets) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: transformers[torch] in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.35.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (3.12.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (0.19.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (4.66.1)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.10 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (2.1.1+cu118)\n",
      "Requirement already satisfied: accelerate>=0.20.3 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (0.24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\yezix\\appdata\\roaming\\python\\python311\\site-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.5.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers[torch]) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers[torch]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers[torch]) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers[torch]) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: tokenizers in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.15.0)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tokenizers) (0.19.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (3.12.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (23.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub<1.0,>=0.16.4->tokenizers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.7.22)\n",
      "Requirement already satisfied: evaluate in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (2.15.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (1.24.3)\n",
      "Requirement already satisfied: dill in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (0.3.7)\n",
      "Requirement already satisfied: pandas in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (2.1.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (4.66.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (0.70.15)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (2023.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (0.19.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (23.1)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->evaluate) (14.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->evaluate) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->evaluate) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->evaluate) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Requirement already satisfied: rouge_score in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rouge_score) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rouge_score) (1.24.3)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->rouge_score) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->rouge_score) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->rouge_score) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->rouge_score) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click->nltk->rouge_score) (0.4.6)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.1.99)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.19.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (3.12.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (2023.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (4.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (23.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub) (2023.7.22)\n",
      "Requirement already satisfied: wandb in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.16.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (3.1.40)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\yezix\\appdata\\roaming\\python\\python311\\site-packages (from wandb) (5.9.5)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (1.36.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (69.0.2)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (4.24.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\yezix\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install datasets\n",
    "!pip install transformers[torch]\n",
    "!pip install tokenizers\n",
    "!pip install evaluate\n",
    "!pip install rouge_score\n",
    "!pip install sentencepiece\n",
    "!pip install huggingface_hub\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "673e826c-17f9-45cf-b600-a0a41d8a33e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yezix\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import sentencepiece\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import T5Tokenizer, DataCollatorForSeq2Seq\n",
    "from transformers import T5ForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import wandb\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a64e28-68b5-489d-97b4-139cbb60c837",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a0a323b-428f-4ca2-88d9-3bd4145031ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yezix\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\t5\\tokenization_t5.py:240: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"t5-base\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "model_math = T5ForConditionalGeneration.from_pretrained(MODEL_NAME).to(device)\n",
    "model_code = T5ForConditionalGeneration.from_pretrained(MODEL_NAME).to(device)\n",
    "model_base = T5ForConditionalGeneration.from_pretrained(MODEL_NAME).to(device)\n",
    "\n",
    "data_collator_math = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_math)\n",
    "data_collator_code = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_code)\n",
    "data_collator_base = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486f8f8f-24af-4ada-addd-a65f1cda6338",
   "metadata": {},
   "source": [
    "## Create datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0633e05f-5423-4e20-8c09-1346d19ef328",
   "metadata": {},
   "source": [
    "### Create general knowledge dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054d926d-b233-4744-9be8-493214b82321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_folder_to_datasetdict_gen(folder_path):\n",
    "\n",
    "    dataset = Dataset.from_dict(folder_path)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0efddf-f8c4-4886-b74e-b3c86e3ab62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_train = convert_folder_to_datasetdict_gen(\"data/general/train.gz\")\n",
    "general_test = convert_folder_to_datasetdict_gen(\"data/general/test.gz\")\n",
    "\n",
    "general_dict = DatasetDict({\n",
    "    'train': general_train,\n",
    "    'test': general_test\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c723f352-aa2e-430f-b835-239807af143e",
   "metadata": {},
   "source": [
    "### Create math dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "64c35803-3c0b-44c0-900b-a5c70864de2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_folder_to_datasetdict_math(folder_path):\n",
    "    data = {\"id\": [], \"question\": [], \"level\": [], \"type\": [], \"answer\": []}\n",
    "\n",
    "    subject_dictionary = {\n",
    "        \"algebra\": 1,\n",
    "        \"counting_and_probability\": 2,\n",
    "        \"geometry\": 3,\n",
    "        \"intermediate_algebra\": 4,\n",
    "        \"number_theory\": 5,\n",
    "        \"prealgebra\": 6,\n",
    "        \"precalculus\": 7\n",
    "    }\n",
    "\n",
    "    for subdir, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            folder_name = os.path.basename(os.path.normpath(subdir))\n",
    "            \n",
    "            with open(file_path, \"r\") as f:\n",
    "                json_data = json.load(f)\n",
    "                problem = json_data.get(\"problem\", \"\")\n",
    "                level = json_data.get(\"level\", \"\")\n",
    "                type_ = json_data.get(\"type\", \"\")\n",
    "                solution = json_data.get(\"solution\", \"\")\n",
    "\n",
    "                # Generate id from subject code and file name\n",
    "                file_name = os.path.splitext(file)[0]\n",
    "                subject_code = subject_dictionary.get(folder_name, 0)  # Default to 0 if not found\n",
    "                id_ = f\"{subject_code}_{file_name}\"\n",
    "\n",
    "                data[\"id\"].append(id_)\n",
    "                data[\"question\"].append(problem)\n",
    "                data[\"level\"].append(level)\n",
    "                data[\"type\"].append(type_)\n",
    "                data[\"answer\"].append(solution)\n",
    "\n",
    "    dataset = Dataset.from_dict(data)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ee114fa9-509b-47d1-9039-ca0679324080",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_train = convert_folder_to_datasetdict_math(\"data/math/train/\")\n",
    "math_test = convert_folder_to_datasetdict_math(\"data/math/test/\")\n",
    "\n",
    "math_dict = DatasetDict({\n",
    "    'train': math_train,\n",
    "    'test': math_test\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e9ab3a02-d628-48df-8434-201d28128ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '1_1000',\n",
       " 'question': 'What is the degree of the polynomial $(4 +5x^3 +100 +2\\\\pi x^4 + \\\\sqrt{10}x^4 +9)$?',\n",
       " 'level': 'Level 3',\n",
       " 'type': 'Algebra',\n",
       " 'answer': \"This polynomial is not written in standard form.  However, we don't need to write it in standard form, nor do we need to pay attention to the coefficients.  We just look for the exponents on $x$.  We have an $x^4$ term and no other term of higher degree, so $\\\\boxed{4}$ is the degree of the polynomial.\"}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_dict[\"train\"][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f3e5ce-60d4-4910-a253-43809da4be7f",
   "metadata": {},
   "source": [
    "### Create code dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a5b4e88-cfee-412d-bc7f-b4ba799b29e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_folder_to_datasetdict_code(folder_path):\n",
    "    data = {\"id\": [], \"question\": [], \"type\": [], \"answer\": []}\n",
    "\n",
    "    for subdir, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            folder_name = os.path.basename(os.path.normpath(subdir))\n",
    "            file_name = os.path.splitext(file)[0]\n",
    "            id_ = f\"{file_name}\"\n",
    "\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "                content = f.readlines()\n",
    "\n",
    "                # Extract comments as questions\n",
    "                comments = [line.strip()[2:] for line in content if line.strip().startswith('//')]\n",
    "                question = '\\n'.join(comments)\n",
    "                # Extract non-commented lines as answers\n",
    "                code_lines = [line.strip() for line in content if not line.strip().startswith('//')]\n",
    "                answer = '\\n'.join(code_lines)\n",
    "\n",
    "                data[\"id\"].append(id_)\n",
    "                data[\"question\"].append(question)\n",
    "                data[\"type\"].append(folder_name)\n",
    "                data[\"answer\"].append(answer)\n",
    "                \n",
    "    dataset = Dataset.from_dict(data)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8a74975-7dca-416b-a4ba-3e077498efb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_dataset = convert_folder_to_datasetdict_code(\"data/code/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "beab82c5-4890-4a4c-9b99-203e2ae145ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_dict = code_dataset.train_test_split(test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58f4e043-85c1-4b18-a5a6-c84fc98d2c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'question', 'type', 'answer'],\n",
       "        num_rows: 126\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'question', 'type', 'answer'],\n",
       "        num_rows: 54\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21f8d63f-ee26-476e-90c1-c2b7c7b69b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'GeneralizedAbbreviation',\n",
       " 'question': ' Write a function to generate the generalized abbreviations of a word.\\n Example:\\n Given word = \"word\", return the following list (order does not matter):\\n [\"word\", \"1ord\", \"w1rd\", \"wo1d\", \"wor1\", \"2rd\", \"w2d\", \"wo2\", \"1o1d\", \"1or1\", \"w1r1\", \"1o2\", \"2r1\", \"3d\", \"w3\", \"4\"]',\n",
       " 'type': 'backtracking',\n",
       " 'answer': '\\n\\npublic class GeneralizedAbbreviation {\\npublic List<String> generateAbbreviations(String word) {\\nList<String> result = new ArrayList<String>();\\n\\nbacktrack(result, word, 0, \"\", 0);\\n\\nreturn result;\\n}\\n\\nvoid backtrack(List result, String word, int position, String current, int count) {\\nif(position == word.length()) {\\nif(count > 0) {\\ncurrent += count;\\n}\\n\\nresult.add(current);\\n} else {\\nbacktrack(result, word, position + 1, current, count + 1);\\nbacktrack(result, word, position + 1, current + (count > 0 ? count : \"\") + word.charAt(position), 0);\\n}\\n}\\n}'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_dict[\"train\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5977fd4e-3fa5-4eff-b855-3af20d8d5288",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c905e62b-8fa0-40a1-8441-041309ba0bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"Please answer this question: \"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "   \"\"\"Add prefix to the sentences, tokenize the text, and set the labels\"\"\"\n",
    "   # The \"inputs\" are the tokenized answer:\n",
    "   inputs = [prefix + doc for doc in examples[\"question\"]]\n",
    "   model_inputs = tokenizer(inputs, max_length=128, truncation=True)\n",
    "  \n",
    "   # The \"labels\" are the tokenized outputs:\n",
    "   labels = tokenizer(text_target=examples[\"answer\"], \n",
    "                      max_length=512,         \n",
    "                      truncation=True)\n",
    "\n",
    "   model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "   return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5355b55-7f8e-45a2-b6d1-91357968dedf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.046640872955322266,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 7500,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1c9acd0464647d084e4be7a7474e365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.027621984481811523,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 5004,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be32992166c4bbf885e679f5fe0a1e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5004 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03834056854248047,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 136,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fde4f9b1e1b498983335c95453d3c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/136 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03414773941040039,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 59,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a4ab5c1bd544a78b9c1cbc7fde89de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/59 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset_math = math_dict.map(preprocess_function, batched=True)\n",
    "tokenized_dataset_code = code_dict.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efdd0266-9885-42ed-8a12-0de5a8cd1070",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"punkt\", quiet=True)\n",
    "metric = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4cd4453a-5b62-4c43-be98-911e0d460396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "   preds, labels = eval_preds\n",
    "\n",
    "   # decode preds and labels\n",
    "   labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "   decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "   decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "   # rougeLSum expects newline after each sentence\n",
    "   decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "   decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "\n",
    "   result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "  \n",
    "   return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecbb6b0-9938-4584-a913-d523357eb3c6",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bec7ac9-d105-4fef-8c5e-131c45951ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Parameters\n",
    "L_RATE = 3e-4\n",
    "BATCH_SIZE = 8\n",
    "PER_DEVICE_EVAL_BATCH = 4\n",
    "WEIGHT_DECAY = 0.01\n",
    "SAVE_TOTAL_LIM = 3\n",
    "NUM_EPOCHS = 3\n",
    "OVERWRITE_OUTPUT_DIR = True\n",
    "LOAD_BEST_MODEL_AT_END = True\n",
    "\n",
    "# Set up training arguments\n",
    "training_args_math = Seq2SeqTrainingArguments(\n",
    "   output_dir=\"./results/math\",\n",
    "   overwrite_output_dir=OVERWRITE_OUTPUT_DIR,\n",
    "   save_strategy=\"epoch\",\n",
    "   evaluation_strategy=\"epoch\",\n",
    "   load_best_model_at_end=LOAD_BEST_MODEL_AT_END,\n",
    "   learning_rate=L_RATE,\n",
    "   per_device_train_batch_size=BATCH_SIZE,\n",
    "   per_device_eval_batch_size=PER_DEVICE_EVAL_BATCH,\n",
    "   weight_decay=WEIGHT_DECAY,\n",
    "   save_total_limit=SAVE_TOTAL_LIM,\n",
    "   num_train_epochs=NUM_EPOCHS,\n",
    "   predict_with_generate=True,\n",
    "   push_to_hub=False\n",
    ")\n",
    "\n",
    "training_args_code = Seq2SeqTrainingArguments(\n",
    "   output_dir=\"./results/code\",\n",
    "   overwrite_output_dir=OVERWRITE_OUTPUT_DIR,\n",
    "   save_strategy=\"epoch\",\n",
    "   evaluation_strategy=\"epoch\",\n",
    "   load_best_model_at_end=LOAD_BEST_MODEL_AT_END,\n",
    "   learning_rate=L_RATE,\n",
    "   per_device_train_batch_size=BATCH_SIZE,\n",
    "   per_device_eval_batch_size=PER_DEVICE_EVAL_BATCH,\n",
    "   weight_decay=WEIGHT_DECAY,\n",
    "   save_total_limit=SAVE_TOTAL_LIM,\n",
    "   num_train_epochs=NUM_EPOCHS,\n",
    "   predict_with_generate=True,\n",
    "   push_to_hub=False\n",
    ")\n",
    "\n",
    "training_args_base = Seq2SeqTrainingArguments(\n",
    "   output_dir=\"./results/base\",\n",
    "   overwrite_output_dir=OVERWRITE_OUTPUT_DIR,\n",
    "   save_strategy=\"epoch\",\n",
    "   evaluation_strategy=\"epoch\",\n",
    "   load_best_model_at_end=LOAD_BEST_MODEL_AT_END,\n",
    "   learning_rate=L_RATE,\n",
    "   per_device_train_batch_size=BATCH_SIZE,\n",
    "   per_device_eval_batch_size=PER_DEVICE_EVAL_BATCH,\n",
    "   weight_decay=WEIGHT_DECAY,\n",
    "   save_total_limit=SAVE_TOTAL_LIM,\n",
    "   num_train_epochs=NUM_EPOCHS,\n",
    "   predict_with_generate=True,\n",
    "   push_to_hub=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79eb7ce-d4d2-433b-8deb-bb660067cf59",
   "metadata": {},
   "source": [
    "### Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "035495c8-f1ed-49c8-8cee-713de3910148",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_math = Seq2SeqTrainer(\n",
    "   model=model_math,\n",
    "   args=training_args_math,\n",
    "   train_dataset=tokenized_dataset_math[\"train\"], \n",
    "   eval_dataset=tokenized_dataset_math[\"test\"],   \n",
    "   tokenizer=tokenizer,\n",
    "   data_collator=data_collator_math,\n",
    "   compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e5a4338-78e9-4357-9b4b-522a9e37ad18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myezixuanclara\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yezix\\Desktop\\2023_Fall\\MIT6.8610\\project\\git\\wandb\\run-20231123_151548-i0svx75r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yezixuanclara/huggingface/runs/i0svx75r' target=\"_blank\">apricot-lion-6</a></strong> to <a href='https://wandb.ai/yezixuanclara/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yezixuanclara/huggingface' target=\"_blank\">https://wandb.ai/yezixuanclara/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yezixuanclara/huggingface/runs/i0svx75r' target=\"_blank\">https://wandb.ai/yezixuanclara/huggingface/runs/i0svx75r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 501/2814 [00:59<04:35,  8.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0484, 'learning_rate': 0.0002466950959488273, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 938/2814 [01:49<03:37,  8.64it/s]c:\\Users\\yezix\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "                                                  \n",
      " 33%|███▎      | 938/2814 [02:47<03:37,  8.64it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0, 'eval_rouge1': 0.0, 'eval_rouge2': 0.0, 'eval_rougeL': 0.0, 'eval_rougeLsum': 0.0, 'eval_runtime': 58.1889, 'eval_samples_per_second': 85.927, 'eval_steps_per_second': 21.482, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 1002/2814 [02:57<03:28,  8.67it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 0.00019339019189765458, 'epoch': 1.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 1501/2814 [03:56<02:49,  7.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 0.00014008528784648186, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 1876/2814 [04:41<01:53,  8.27it/s]c:\\Users\\yezix\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "                                                   \n",
      " 67%|██████▋   | 1876/2814 [05:40<01:53,  8.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0, 'eval_rouge1': 0.0, 'eval_rouge2': 0.0, 'eval_rougeL': 0.0, 'eval_rougeLsum': 0.0, 'eval_runtime': 59.3238, 'eval_samples_per_second': 84.283, 'eval_steps_per_second': 21.071, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 2002/2814 [05:57<01:31,  8.85it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 8.678038379530917e-05, 'epoch': 2.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 2502/2814 [06:54<00:35,  8.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 3.347547974413646e-05, 'epoch': 2.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2814/2814 [07:31<00:00,  8.96it/s]c:\\Users\\yezix\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "                                                   \n",
      "100%|██████████| 2814/2814 [08:32<00:00,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0, 'eval_rouge1': 0.0, 'eval_rouge2': 0.0, 'eval_rougeL': 0.0, 'eval_rougeLsum': 0.0, 'eval_runtime': 61.2103, 'eval_samples_per_second': 81.686, 'eval_steps_per_second': 20.421, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n",
      "100%|██████████| 2814/2814 [08:36<00:00,  5.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 518.6125, 'train_samples_per_second': 43.385, 'train_steps_per_second': 5.426, 'train_loss': 0.00859833234957453, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2814, training_loss=0.00859833234957453, metrics={'train_runtime': 518.6125, 'train_samples_per_second': 43.385, 'train_steps_per_second': 5.426, 'train_loss': 0.00859833234957453, 'epoch': 3.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_math.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model_math\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41385fbe-3c12-4db7-8e08-3484cecbcd9c",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff2688bf-59de-448b-be88-84cec4e22588",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_code = Seq2SeqTrainer(\n",
    "   model=model_code,\n",
    "   args=training_args_code,\n",
    "   train_dataset=tokenized_dataset_code[\"train\"],    \n",
    "   eval_dataset=tokenized_dataset_code[\"test\"],    \n",
    "   tokenizer=tokenizer,\n",
    "   data_collator=data_collator_code,\n",
    "   compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f0f303a-81ea-4ddb-b787-e3c5853976de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 16/48 [03:28<07:55, 14.87s/it]c:\\Users\\yezix\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "\n",
      " 33%|███▎      | 16/48 [03:47<07:55, 14.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.496579885482788, 'eval_rouge1': 0.03383376969610924, 'eval_rouge2': 0.0016460905349794238, 'eval_rougeL': 0.028476556253146653, 'eval_rougeLsum': 0.029104003651678312, 'eval_runtime': 18.5042, 'eval_samples_per_second': 2.918, 'eval_steps_per_second': 0.757, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 32/48 [07:24<02:47, 10.45s/it]c:\\Users\\yezix\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "\n",
      " 67%|██████▋   | 32/48 [07:42<02:47, 10.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.085508108139038, 'eval_rouge1': 0.14193502014963366, 'eval_rouge2': 0.05224203937530196, 'eval_rougeL': 0.1311783087726054, 'eval_rougeLsum': 0.1319044507434023, 'eval_runtime': 18.0557, 'eval_samples_per_second': 2.991, 'eval_steps_per_second': 0.775, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [10:58<00:00, 12.77s/it]c:\\Users\\yezix\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "\n",
      "100%|██████████| 48/48 [11:16<00:00, 12.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.9809935092926025, 'eval_rouge1': 0.1505172341955189, 'eval_rouge2': 0.05507006806796853, 'eval_rougeL': 0.1411070353465603, 'eval_rougeLsum': 0.1417876510239457, 'eval_runtime': 18.1912, 'eval_samples_per_second': 2.968, 'eval_steps_per_second': 0.77, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n",
      "100%|██████████| 48/48 [11:22<00:00, 14.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 682.7185, 'train_samples_per_second': 0.554, 'train_steps_per_second': 0.07, 'train_loss': 2.8900632858276367, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=48, training_loss=2.8900632858276367, metrics={'train_runtime': 682.7185, 'train_samples_per_second': 0.554, 'train_steps_per_second': 0.07, 'train_loss': 2.8900632858276367, 'epoch': 3.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_code.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model_code\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
